{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "path = Path(current_dir)\n",
    "BASE_DIR = path.parent  # Go one level up\n",
    "\n",
    "load_dotenv(BASE_DIR / \".env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "MILVUS_URL = os.getenv(\"MILVUS_URL\")\n",
    "MILVUS_METRIC_TYPE = os.getenv(\"MILVUS_METRIC_TYPE\")\n",
    "COLLECTION_NAME = os.getenv(\"COLLECTION_NAME\")\n",
    "\n",
    "EMBEDDING_MODEL = os.getenv(\"EMBEDDING_MODEL\")\n",
    "MISTRAL_API_KEY = os.getenv(\"MISTRAL_API_KEY\")\n",
    "LLM_MODEL = os.getenv(\"LLM_MODEL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from mistralai import Mistral\n",
    "import time\n",
    "\n",
    "\n",
    "# Initialize Mistral client\n",
    "client = Mistral(api_key=MISTRAL_API_KEY)\n",
    "\n",
    "\n",
    "# Process a single PDF file using Mistral OCR\n",
    "def process_pdf_with_ocr(file_path):\n",
    "    try:\n",
    "        # Upload the PDF file to Mistral\n",
    "        print(f\"Uploading {file_path}...\")\n",
    "        with open(file_path, \"rb\") as f:\n",
    "            uploaded_pdf = client.files.upload(\n",
    "                file={\n",
    "                    \"file_name\": os.path.basename(file_path),\n",
    "                    \"content\": f,\n",
    "                },\n",
    "                purpose=\"ocr\"\n",
    "            )\n",
    "        \n",
    "        # Get the signed URL for the uploaded file\n",
    "        signed_url = client.files.get_signed_url(file_id=uploaded_pdf.id)\n",
    "        \n",
    "        # Process the PDF with OCR\n",
    "        print(f\"Processing OCR for {file_path}...\")\n",
    "        ocr_response = client.ocr.process(\n",
    "            model=\"mistral-ocr-latest\",\n",
    "            document={\n",
    "                \"type\": \"document_url\",\n",
    "                \"document_url\": signed_url.url,\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        # Extract the text content from the OCR response\n",
    "        # The actual structure depends on Mistral's API response format\n",
    "        # This is a placeholder - adjust based on actual API response structure\n",
    "        extracted_text = ocr_response.pages\n",
    "        \n",
    "        print(ocr_response.pages)\n",
    "\n",
    "        return extracted_text\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {str(e)}\")\n",
    "        return \"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\surya\\Downloads\\Rapi\\Vanessa\\server_latest\\AR-RAG-Project-Server-Docker\\documents_RAG\\iTNC530 機械操作手冊 MV154,MV154APC,MV204,UX300.pdf\n"
     ]
    }
   ],
   "source": [
    "document_path = os.path.join(BASE_DIR, \"documents_RAG\", \"iTNC530 機械操作手冊 MV154,MV154APC,MV204,UX300.pdf\")\n",
    "pdf_text = process_pdf_with_ocr(document_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming pdf_text is a list of OCRPageObject elements\n",
    "markdowns = [page.markdown for page in pdf_text]\n",
    "\n",
    "# If you want to join all markdowns together into one single string (optional):\n",
    "all_markdown = \"\\n\".join(markdowns)\n",
    "\n",
    "# Display or process the extracted markdowns\n",
    "print(all_markdown)\n",
    "\n",
    "extracted_markdown=all_markdown   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recursive function to split text into manageable chunks with overlap (kept from original code)\n",
    "def recursive_chunk_text(text, chunk_size=1000, overlap=150):\n",
    "    chunks = []\n",
    "    \n",
    "    # Base case: if the text is smaller than chunk_size, return it as is\n",
    "    if len(text) <= chunk_size:\n",
    "        chunks.append(text)\n",
    "        return chunks\n",
    "    \n",
    "    # Try splitting the text at the closest space to avoid cutting words\n",
    "    split_point = text.rfind(' ', 0, chunk_size)\n",
    "    \n",
    "    # If no space is found, just split at the chunk_size\n",
    "    if split_point == -1:\n",
    "        split_point = chunk_size\n",
    "    \n",
    "    # Split the text and add the first chunk\n",
    "    chunks.append(text[:split_point].strip())\n",
    "    \n",
    "    # Calculate the starting point for the next chunk (with overlap)\n",
    "    next_start = max(0, split_point - overlap)\n",
    "    \n",
    "    # Recursively process the remaining part, including the overlap\n",
    "    chunks.extend(recursive_chunk_text(text[next_start:].strip(), chunk_size, overlap))\n",
    "    \n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract text from PDF files using Mistral OCR\n",
    "text_lines = []\n",
    "for file_path in glob(os.path.join(BASE_DIR, \"documents_RAG\", \"*.pdf\"), recursive=True):\n",
    "    # Process the PDF file with OCR\n",
    "    pdf_text = process_pdf_with_ocr(file_path)\n",
    "    \n",
    "    # Apply recursive chunking to split the extracted text into smaller sections\n",
    "    if pdf_text:\n",
    "        text_lines.extend(recursive_chunk_text(extracted_markdown))\n",
    "        \n",
    "        # Add a delay between API calls to avoid rate limiting\n",
    "        time.sleep(1)\n",
    "\n",
    "# Write all the chunks to a text file for external viewing\n",
    "with open(\"chunks_output.txt\", \"w\") as file:\n",
    "    for i, chunk in enumerate(text_lines):\n",
    "        file.write(f\"Chunk {i+1}:\\n{chunk}\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "\n",
    "def emb_text(text):\n",
    "    response = ollama.embeddings(model=EMBEDDING_MODEL, prompt=text)\n",
    "    return response[\"embedding\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_embedding = emb_text(\"This is a test\")\n",
    "embedding_dim = len(test_embedding)\n",
    "print(embedding_dim)\n",
    "print(test_embedding[:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Extracted Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# BLASER \n",
      "\n",
      "## we cut faster\n",
      "\n",
      "## USER MANUAL\n",
      "\n",
      "## FOR <br> MV154 / MV154APC series, MV204 series \\& UX300 <br> Heidenhain iTNC530\n",
      "# CONTENTS \n",
      "\n",
      "1. Safety ..... 5\n",
      "1.1 Intended Use ..... 5\n",
      "1.2 Important Safety Notice and Warning ..... 5\n",
      "1.2.1 Safe installation ..... 5\n",
      "1.2.2 Machine guarding ..... 6\n",
      "1.2.3 Software ..... 6\n",
      "1.2.4 Authorized personnel and training ..... 6\n",
      "1.2.5 Safe working practice ..... 6\n",
      "1.3 Safety Cautions List ..... 7\n",
      "1.4 Safety Devices ..... 10\n",
      "1.4.1 Emergency Stop ..... 10\n",
      "1.4.2 Guard ..... 10\n",
      "1.4.3 Window ..... 11\n",
      "1.4.4 Door Interlock ..... 11\n",
      "1.4.5 Cabinet door switch ..... 11\n",
      "1.5 Warning Labels ..... 12\n",
      "1.6 Residual Risks ..... 12\n",
      "2. Introduction ..... 13\n",
      "2.1 Consumption Material ..... 13\n",
      "2.1.1 Lubrication oil for linear rail and ballscrew ..... 13\n",
      "2.1.2 Lubrication oil for pneumatic system ..... 13\n",
      "2.1.3 Cutting fluid ..... 13\n",
      "2.1.4 Filter for cutting fluid ..... 13\n",
      "2.1.5 Coolant of cooler ..... 14\n",
      "2.2 Operation Panel ..... 15\n",
      "2.3 Buttons/Knobs on chip conveyor\n",
      "luid ..... 13\n",
      "2.1.4 Filter for cutting fluid ..... 13\n",
      "2.1.5 Coolant of cooler ..... 14\n",
      "2.2 Operation Panel ..... 15\n",
      "2.3 Buttons/Knobs on chip conveyor ..... 17\n",
      "2.4 Buttons/Knobs for Tool Magazine ..... 17\n",
      "2.5 Spindle Tooling ..... 17\n",
      "2.6 Tool Magazine and ATC ..... 20\n",
      "2.7 Cooling System ..... 20\n",
      "2.8 Chip Removal ..... 20\n",
      "3. Installation ..... 21\n",
      "3.1 Foundation Preparation ..... 21\n",
      "3.2 Power Preparation ..... 21\n",
      "3.2.1 Line Configuration ..... 21\n",
      "3.3 Unpacking ..... 22\n",
      "3.4 Machine Lifting ..... 22\n",
      "3.5 Leveling of Machine ..... 22\n",
      "3.6 Before Power ON ..... 22\n",
      "3.6.1 Grounding ..... 22\n",
      "3.6.2 Power connection ..... 24\n",
      "3.6.3 Misc. ..... 25\n",
      "3.7 First Time Power ON ..... 26\n",
      "3.7.1 Rotation Direction of Motors ..... 26\n",
      "3.7.2 Spindle Run-in. ..... 26\n",
      "4. Operation ..... 27\n",
      "4.1 Power ON/OFF ..... 27\n",
      "4.2 Reference the Machine ..... 27\n",
      "4.3 Worklight ON/OFF ..... 28\n",
      "4.4 Machine Warm-up ..... 28\n",
      "4.5 Spindle Operation ..... 28\n",
      "4.6 Spindle Warm-up ..... 29\n",
      "4.7 Interrupting Operation ..... 29\n",
      "4.8 Jobs\n",
      "ON/OFF ..... 28\n",
      "4.4 Machine Warm-up ..... 28\n",
      "4.5 Spindle Operation ..... 28\n",
      "4.6 Spindle Warm-up ..... 29\n",
      "4.7 Interrupting Operation ..... 29\n",
      "4.8 Jobs Finished ..... 29\n",
      "4.9 Jog Axis. ..... 30\n",
      "4.10 Jog Axis by MPG ..... 32\n",
      "4.11 Tool Data Setting ..... 34\n",
      "4.12 Work Coordinate Setting ..... 35\n",
      "4.13 Door Interlock Overriding ..... 36\n",
      "4.14 Tool Loading/Unloading ..... 37\n",
      "4.15 ATC Operation ..... 37\n",
      "4.16 Coolant Operation ..... 38\n",
      "4.17 Chip Removal Operation ..... 38\n",
      "4.18 Auto Pallet Change System ..... 38\n",
      "5. Maintenance ..... 39\n",
      "5.1 Routine Inspection ..... 40\n",
      "5.1.1 Daily ..... 40\n",
      "5.1.2 Weekly (In addition to daily routine) ..... 40\n",
      "5.1.3 Yearly (In addition to weekly routine) ..... 40\n",
      "5.2 Lubrication ..... 40\n",
      "5.2.1 Automatic Lubrication System ..... 40\n",
      "5.2.2 FRL unit ..... 41\n",
      "5.3 Cleaning ..... 41\n",
      "5.3.1 Machine Interior: ..... 41\n",
      "5.3.2 Coolant Filtering: ..... 41\n",
      "6. Trouble shooting ..... 42\n",
      "6.1 ATC system: ..... 42\n",
      "6.2 Cooling, Coolant and lubrication system. ..... 42\n",
      "6.3 Door switch\n"
     ]
    }
   ],
   "source": [
    "# Read the saved text chunks from the file\n",
    "text_chunks = []\n",
    "\n",
    "with open(os.path.join(BASE_DIR, 'data', 'processed', 'chunks_output.txt'), \"r\", encoding=\"utf-8\") as file:\n",
    "    chunk = \"\"\n",
    "    for line in file:\n",
    "        # Detect new chunk start\n",
    "        if line.startswith(\"Chunk \"):\n",
    "            if chunk:\n",
    "                text_chunks.append(chunk.strip())  # Save previous chunk\n",
    "            chunk = \"\"  # Start new chunk\n",
    "        else:\n",
    "            chunk += line  # Append line to chunk\n",
    "\n",
    "    # Save the last chunk\n",
    "    if chunk:\n",
    "        text_chunks.append(chunk.strip())\n",
    "\n",
    "# Print first 3 chunks for verification\n",
    "print(\"\\n\".join(text_chunks[:3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "\n",
    "def emb_text(text):\n",
    "    response = ollama.embeddings(model=EMBEDDING_MODEL, prompt=text)\n",
    "    return response[\"embedding\"]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1024\n",
      "[0.2327725738286972, 0.42580944299697876, 0.19741831719875336, 0.4612889289855957, -0.4603482782840729, -0.14149177074432373, -0.18266350030899048, -0.07604783028364182, 0.39978229999542236, 0.8336597681045532]\n"
     ]
    }
   ],
   "source": [
    "test_embedding = emb_text(\"This is a test\")\n",
    "embedding_dim = len(test_embedding)\n",
    "print(embedding_dim)\n",
    "print(test_embedding[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75\n"
     ]
    }
   ],
   "source": [
    "# EMBED TEXT\n",
    "embedding_vectors = [emb_text(text_chunk) for text_chunk in text_chunks]\n",
    "print(len(embedding_vectors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement pickle (from versions: none)\n",
      "ERROR: No matching distribution found for pickle\n",
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(os.path.join(BASE_DIR, 'data', 'processed', 'embeddings.pkl'), 'wb') as f:\n",
    "    pickle.dump(embedding_vectors, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to Milvus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymilvus import Collection, FieldSchema, CollectionSchema, DataType, Index, utility, connections\n",
    "import numpy as np\n",
    "import fitz\n",
    "from glob import glob\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Milvus!\n"
     ]
    }
   ],
   "source": [
    "# Connect to milvus\n",
    "connections.connect(alias=\"default\", uri=MILVUS_URL)\n",
    "print(\"Connected to Milvus!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existing collection vanessa_rag_collection dropped!\n"
     ]
    }
   ],
   "source": [
    "# Drop existing collection if it exists\n",
    "if utility.has_collection(COLLECTION_NAME):\n",
    "    utility.drop_collection(COLLECTION_NAME)\n",
    "    print(f\"Existing collection {COLLECTION_NAME} dropped!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Koleksi 'vanessa_rag_collection' berhasil dibuat!\n"
     ]
    }
   ],
   "source": [
    "# Define schema\n",
    "fields = [\n",
    "    FieldSchema(name=\"file_uuid\", dtype=DataType.VARCHAR, max_length=36, is_primary=True),\n",
    "    FieldSchema(name=\"text\", dtype=DataType.VARCHAR, max_length=2048),\n",
    "    FieldSchema(name=\"vector\", dtype=DataType.FLOAT_VECTOR, dim=get_embedding_dimension())\n",
    "]\n",
    "\n",
    "schema = CollectionSchema(fields, description=\"Koleksi embedding dokumen\")\n",
    "\n",
    "# Create new collection\n",
    "collection = Collection(name=COLLECTION_NAME, schema=schema, consistency_level=\"Strong\")\n",
    "print(f\"Koleksi '{COLLECTION_NAME}' berhasil dibuat!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index berhasil dibuat!\n"
     ]
    }
   ],
   "source": [
    "# Create index on vector field\n",
    "index_params = {\n",
    "    \"metric_type\": MILVUS_METRIC_TYPE,\n",
    "    \"index_type\": \"IVF_FLAT\",\n",
    "    \"params\": {\"nlist\": 128}\n",
    "}\n",
    "\n",
    "collection.create_index(field_name=\"vector\", index_params=index_params)\n",
    "print(\"Index berhasil dibuat!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing embeddings: 75it [00:00, 136178.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data berhasil dimasukkan dengan total 75 chunk.\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Correct list comprehension\n",
    "entities = [\n",
    "    {\n",
    "        \"text\": text,\n",
    "        \"vector\": vector\n",
    "    }\n",
    "    for i, (text, vector) in enumerate(tqdm(zip(text_chunks, embedding_vectors), desc=\"Processing embeddings\"))\n",
    "]\n",
    "\n",
    "# Insert into Milvus\n",
    "insert_result = collection.insert(entities)\n",
    "collection.flush()\n",
    "collection.load()\n",
    "print(f\"Data berhasil dimasukkan dengan total {len(text_chunks)} chunk.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 166.4105224609375, Text: n and acted upon.\n",
      "DON'T run the machine until you have made clear to your supervisor that you understand the potential hazard of spindle rotation, the throwing of coolant and the throwing of swarf from the cutting process.\n",
      "DON'T run the machine until you have read and understood all manuals provided with the machine.\n",
      "DON'T run the machine until you have read and understood all the machine and control keys.\n",
      "DON'T run the machine for the first time without a qualified instructor. Ask your supervisor for help when you need it.\n",
      "PROTECT your eyes. Wear safety glasses with side shields at all times.\n",
      "DON'T get caught in moving parts. Remove watches, rings, jewellery, neckties and loose fitting clothes.\n",
      "PROTECT your head. Wear a safety helmet when working near overhead hazards.\n",
      "KEEP your hair away from moving parts.\n",
      "PROTECT your feet. Always wear safety shoes with steel toes and oil resistant soles.\n",
      "Gloves are easily caught in moving parts. TAKE THEM OFF before you turns on the machine.\n",
      "Loose\n",
      "Score: 159.57400512695312, Text: . Make sure the spindle is stopped before manually adjusting the work piece or fixture or coolant nozzle.\n",
      "PROTECT your hands. Make sure the spindle is stopped before you take measurements.\n",
      "PROTECT your hands. Make sure the spindle is stopped before you move a safeguard. Never reach round a safeguard.\n",
      "PROTECT your hands. Make sure the machine is switched off and electrically isolated before making any mechanical adjustment.\n",
      "PROTECT your hands. Beware sharp edges of cutting tools when changing and handling tools.\n",
      "PROTECT your eyes and the machine. Never use a compressed air hose to remove swarf or to clean out air vents.\n",
      "KEEP the work area well lighted. Ask for additional lighting if needed.\n",
      "DON'T slip. Keep your work area clean and dry. Remove swarf, oil and obstacles.\n",
      "NEVER lean on the machine. Stand away when machine is running. DON'T get trapped. Avoid pinch points caused between other machines and the machine you are working.\n",
      "PREVENT objects from flying loose. Securely clamp and\n",
      "Score: 158.62820434570312, Text: CTION. PRESS MODE -> HELP soft key, enter help function with service screen. Follow with each instruction to do ATC service job.\n",
      "\\#301 S to toolchange position\n",
      "\\#302 Z to toolchange position\n",
      "\\#305 Tool unclamping\n",
      "\\#306 Tool clamping\n",
      "\\#309 Tool pocket put out\n",
      "\\#310 Tool pocket put in\n",
      "\\#311 Tool arm to unclamping pos\n",
      "\\#312 Tool arm to clamping pos\n",
      "\\#313 Tool arm to basic pos\n",
      "\\#314 Tool arm back to clamping pos\n",
      "\\#315 Tool arm back to unclamping pos\n",
      "\\#316 Tool arm back to basic pos\n",
      "\\#317 Magazine turn cw (right)\n",
      "\\#318 Magazine turn ccw (left)\n",
      "\\#319 Magazine reference\n",
      "\\#320 Delete spindle status (TO)\n",
      "iTNC 530 Provides HELP SCREEN function for :\n",
      "\n",
      "- Set -up tools as installation if need restart adjust tools.\n",
      "- Trouble-shooting as :\n",
      "\n",
      "1. EMG-stop button has been pressed.\n",
      "2. Air supply has lost suddenly or pressure too low .\n",
      "3. Mechanical interference.\n",
      "4. Power shut off suddenly.\n",
      "\n",
      "## WARNING!\n",
      "\n",
      "Each step has set up carefully through PLC protection, alarm will display upper, lower to show message\n",
      "Score: 158.35736083984375, Text: fuses, cable's etc. from reputable recognized manufacturers.\n",
      "\n",
      "## CAUTION!\n",
      "\n",
      "The maintenance person should check that the machine operates safety after the work is completed. Maintenance and inspection data should be recorded and kept for reference.\n",
      "# 5.1 Routine Inspection \n",
      "\n",
      "### 5.1.1 Daily\n",
      "\n",
      "1. Check pressure gauges for proper reading. Air pressure 5.5 bar (80psi). Hydraulic pressure 68bar (986psi)\n",
      "2. Check that there is sufficient oil in the air lubricator.\n",
      "3. Check motors and other parts for abnormal noises.\n",
      "4. Check the lubrication of sliding parts for evidence of proper lubrication.\n",
      "5. Check safety covers and safety devices for proper operation.\n",
      "6. Check coolant level and fill as necessary.\n",
      "7. Clean dirt and chips from the axes and empty the swarf trays.\n",
      "5.1.2 Weekly (In addition to daily routine)\n",
      "8. Clean chips and dirt from the entire machine and wipe down.\n",
      "9. Check the air filter at the rear of the electrical cabinet. Replace the filter element if it is contaminated.\n",
      "10. Check\n",
      "Score: 157.7305450439453, Text: ay documentation of the inputs and outputs\n",
      "\n",
      "| PLC Output/Input |  |\n",
      "| :--: | :--: |\n",
      "| I_Taste_NC_Start | $12132=0$ |\n",
      "| I_Taste_NC_Stop | $12131=1$ |\n",
      "| I_Taste_NC_Stop_Rchsen | $1 M 3999=1$ |\n",
      "| I_Taste_Eligang | $12141=0$ |\n",
      "| 0_Lampe_NC_Start | $1016=0$ |\n",
      "| 0_Lampe_NC_Stop | $1017=1$ |\n",
      "| I_Taste_Spindel_Start | $12142=0$ |\n",
      "| I_Taste_Spindel_Stop | $12143=0$ |\n",
      "| 0_Lampe_Spindel_Stop | $105=1$ |\n",
      "| 0_Lampe_Spindel_Start | $106=0$ |\n",
      "| I_Taste_Rchsen_Freifahren | $1 M 3226=0$ |\n",
      "| 0_Lampe_Rchsen_Freifahren | $1 M 3344=0$ |\n",
      "| Page down | (Page 1 of 21) |\n",
      "\n",
      "![img-43.jpeg](img-43.jpeg)\n",
      "Protect Key: When turned to ' 1 ', it will not be possible to edit the following:\n",
      "NC program\n",
      "Data tables\n",
      "![img-44.jpeg](img-44.jpeg)\n",
      "\n",
      "Offset values\n",
      "Work co-ordinates\n",
      "Macro values\n",
      "To enable editing of the above, turn the key to ' 0 '\n",
      "# 7.5 M-function Codes \n",
      "\n",
      "|  | Function Description |\n",
      "| :--: | :--: |\n",
      "| MOO | Program stop, spindle \\& coolant. |\n",
      "| MO1 | Optional Program stop, spindle \\& coolant. |\n",
      "| MO2 | End of\n"
     ]
    }
   ],
   "source": [
    "search_params = {\"metric_type\": \"IP\", \"params\": {\"nprobe\": 3}}\n",
    "\n",
    "query_text = \"This manual is a guide\"\n",
    "query_vector = ollama.embeddings(model=EMBEDDING_MODEL, prompt=query_text)[\"embedding\"]\n",
    "\n",
    "results = collection.search(\n",
    "    data=[query_vector],  # Query vector(s)\n",
    "    anns_field=\"vector\",  # The field to search\n",
    "    param=search_params,\n",
    "    limit=5,  # Get top 5 results\n",
    "    output_fields=[\"text\"]  # Retrieve associated text\n",
    ")\n",
    "\n",
    "# Print the results\n",
    "for hits in results:\n",
    "    for hit in hits:\n",
    "        print(f\"Score: {hit.distance}, Text: {hit.entity.get('text')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".myvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
