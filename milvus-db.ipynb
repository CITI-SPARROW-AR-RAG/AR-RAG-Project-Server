{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "MILVUS_URL = os.getenv(\"MILVUS_URL\")\n",
    "COLLECTION_NAME = os.getenv(\"COLLECTION_NAME\")\n",
    "EMBEDDING_MODEL = os.getenv(\"EMBEDDING_MODEL\")\n",
    "DOCUMENTS_PATH = os.getenv(\"DOCUMENTS_PATH\")\n",
    "MISTRAL_API_KEY = os.getenv(\"MISTRAL_API_KEY\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "from mistralai import Mistral\n",
    "import time\n",
    "\n",
    "\n",
    "# Initialize Mistral client\n",
    "client = Mistral(api_key=MISTRAL_API_KEY)\n",
    "\n",
    "\n",
    "\n",
    "# Process a single PDF file using Mistral OCR\n",
    "def process_pdf_with_ocr(file_path):\n",
    "    try:\n",
    "        # Upload the PDF file to Mistral\n",
    "        print(f\"Uploading {file_path}...\")\n",
    "        with open(file_path, \"rb\") as f:\n",
    "            uploaded_pdf = client.files.upload(\n",
    "                file={\n",
    "                    \"file_name\": os.path.basename(file_path),\n",
    "                    \"content\": f,\n",
    "                },\n",
    "                purpose=\"ocr\"\n",
    "            )\n",
    "        \n",
    "        # Get the signed URL for the uploaded file\n",
    "        signed_url = client.files.get_signed_url(file_id=uploaded_pdf.id)\n",
    "        \n",
    "        # Process the PDF with OCR\n",
    "        print(f\"Processing OCR for {file_path}...\")\n",
    "        ocr_response = client.ocr.process(\n",
    "            model=\"mistral-ocr-latest\",\n",
    "            document={\n",
    "                \"type\": \"document_url\",\n",
    "                \"document_url\": signed_url.url,\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        # Extract the text content from the OCR response\n",
    "        # The actual structure depends on Mistral's API response format\n",
    "        # This is a placeholder - adjust based on actual API response structure\n",
    "        extracted_text = ocr_response.pages\n",
    "        \n",
    "        print(ocr_response.pages)\n",
    "\n",
    "        return extracted_text\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {str(e)}\")\n",
    "        return \"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_text = process_pdf_with_ocr(\"./documents_RAG/iTNC530 機械操作手冊 MV154,MV154APC,MV204,UX300.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming pdf_text is a list of OCRPageObject elements\n",
    "markdowns = [page.markdown for page in pdf_text]\n",
    "\n",
    "# If you want to join all markdowns together into one single string (optional):\n",
    "all_markdown = \"\\n\".join(markdowns)\n",
    "\n",
    "# Display or process the extracted markdowns\n",
    "print(all_markdown)\n",
    "\n",
    "extracted_markdown=all_markdown   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recursive function to split text into manageable chunks with overlap (kept from original code)\n",
    "def recursive_chunk_text(text, chunk_size=1000, overlap=150):\n",
    "    chunks = []\n",
    "    \n",
    "    # Base case: if the text is smaller than chunk_size, return it as is\n",
    "    if len(text) <= chunk_size:\n",
    "        chunks.append(text)\n",
    "        return chunks\n",
    "    \n",
    "    # Try splitting the text at the closest space to avoid cutting words\n",
    "    split_point = text.rfind(' ', 0, chunk_size)\n",
    "    \n",
    "    # If no space is found, just split at the chunk_size\n",
    "    if split_point == -1:\n",
    "        split_point = chunk_size\n",
    "    \n",
    "    # Split the text and add the first chunk\n",
    "    chunks.append(text[:split_point].strip())\n",
    "    \n",
    "    # Calculate the starting point for the next chunk (with overlap)\n",
    "    next_start = max(0, split_point - overlap)\n",
    "    \n",
    "    # Recursively process the remaining part, including the overlap\n",
    "    chunks.extend(recursive_chunk_text(text[next_start:].strip(), chunk_size, overlap))\n",
    "    \n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract text from PDF files using Mistral OCR\n",
    "text_lines = []\n",
    "for file_path in glob(os.path.join(DOCUMENTS_PATH, \"*.pdf\"), recursive=True):\n",
    "    # Process the PDF file with OCR\n",
    "    pdf_text = process_pdf_with_ocr(file_path)\n",
    "    \n",
    "    # Apply recursive chunking to split the extracted text into smaller sections\n",
    "    if pdf_text:\n",
    "        text_lines.extend(recursive_chunk_text(extracted_markdown))\n",
    "        \n",
    "        # Add a delay between API calls to avoid rate limiting\n",
    "        time.sleep(1)\n",
    "\n",
    "# Write all the chunks to a text file for external viewing\n",
    "with open(\"chunks_output.txt\", \"w\") as file:\n",
    "    for i, chunk in enumerate(text_lines):\n",
    "        file.write(f\"Chunk {i+1}:\\n{chunk}\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "\n",
    "def emb_text(text):\n",
    "    response = ollama.embeddings(model=EMBEDDING_MODEL, prompt=text)\n",
    "    return response[\"embedding\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768\n",
      "[1.0914263725280762, 0.5967336893081665, -3.9346163272857666, -0.6990123391151428, 1.5423402786254883, -0.13473758101463318, 0.8982678651809692, -0.46930229663848877, 0.9009982347488403, -0.6395869851112366]\n"
     ]
    }
   ],
   "source": [
    "test_embedding = emb_text(\"This is a test\")\n",
    "embedding_dim = len(test_embedding)\n",
    "print(embedding_dim)\n",
    "print(test_embedding[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymilvus import MilvusClient\n",
    "\n",
    "milvus_client = MilvusClient(uri=MILVUS_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if milvus_client.has_collection(COLLECTION_NAME):\n",
    "    milvus_client.drop_collection(COLLECTION_NAME)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "milvus_client.create_collection(\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    dimension=embedding_dim,\n",
    "    metric_type=\"IP\",  # Inner product distance\n",
    "    consistency_level=\"Strong\",  # Strong consistency level\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating embeddings: 100%|██████████| 72/72 [00:04<00:00, 14.99it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'insert_count': 72, 'ids': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71], 'cost': 0}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "data = []\n",
    "\n",
    "for i, line in enumerate(tqdm(text_lines, desc=\"Creating embeddings\")):\n",
    "    data.append({\"id\": i, \"vector\": emb_text(line), \"text\": line})\n",
    "\n",
    "milvus_client.insert(collection_name=COLLECTION_NAME, data=data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
